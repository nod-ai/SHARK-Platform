name: Llama Benchmarking Tests

on:
  workflow_dispatch:
  schedule:
    # Weekdays at 12:00 AM UTC = 05:00 PST / 06:00 PDT.
    - cron: "0 0 * * 1-5"

concurrency:
  # A PR number if a pull request and otherwise the commit hash. This cancels
  # queued and in-progress runs for the same PR (presubmit) or commit
  # (postsubmit). The workflow name is prepended to avoid conflicts between
  # different workflows.
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

jobs:
  test_llama:
    name: "Llama Benchmarking Tests"
    strategy:
      matrix:
        version: [3.11]
        os: [llama-mi300]
      fail-fast: false
    runs-on: ${{matrix.os}}
    defaults:
      run:
        shell: bash
    env:
      PIP_CACHE_DIR: "${{ github.workspace }}/.pip-cache"
      VENV_DIR: ${{ github.workspace }}/.venv
      SHARK_PLATFORM_REPO_ROOT: ${{ github.workspace }}
    steps:
      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@v3
        with:
          python-version: ${{matrix.version}}

      - name: "Checkout Code"
        uses: actions/checkout@v3

      - name: Cache Pip Packages
        uses: actions/cache@v4
        id: cache-pip
        with:
          path: ${{ env.PIP_CACHE_DIR }}
          key: pip-${{ steps.setup_python.outputs.python-version }}-${{ hashFiles('*requirements.txt') }}

      - name: Install pip deps
        run: |
          python -m pip install --no-compile --upgrade pip
          # Note: We install in three steps in order to satisfy requirements
          # from non default locations first. Installing the PyTorch CPU
          # wheels saves multiple minutes and a lot of bandwidth on runner setup.
          pip install --no-compile -r pytorch-cpu-requirements.txt
          pip install --no-compile -f https://iree.dev/pip-release-links.html --src deps \
            -e "git+https://github.com/iree-org/iree-turbine.git#egg=iree-turbine"
          pip install --no-compile -r requirements.txt -e sharktank/

          # Try with the latest nightly releases, not what iree-turbine pins.
          # We could also pin to a known working or stable version.
          # This should eventually stabilize. Do the best we can for now.
          pip install -f https://iree.dev/pip-release-links.html --upgrade \
            iree-compiler \
            iree-runtime \
            "numpy<2.0"

      - name: Run llama test
        run: pytest sharktank/tests/models/llama/benchmark-tests.py -v -s --longrun

      - name: Upload llama executable files
        uses: actions/upload-artifact@v4
        with:
          name: llama-files
          path: ${{ github.workspace }}/files/
