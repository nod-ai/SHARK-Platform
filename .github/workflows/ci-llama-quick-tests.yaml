# Copyright 2024 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: Llama Benchmarking 8B Tests

on:
  workflow_dispatch:
  pull_request:
  push:
    branches:
      - main

concurrency:
  # A PR number if a pull request and otherwise the commit hash. This cancels
  # queued and in-progress runs for the same PR (presubmit) or commit
  # (postsubmit). The workflow name is prepended to avoid conflicts between
  # different workflows.
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

jobs:
  test_llama_quick:
    name: "Llama Benchmarking 8B Tests"
    strategy:
      matrix:
        version: [3.11]
      fail-fast: false
    runs-on: llama-mi300x-1
    defaults:
      run:
        shell: bash
    env:
      PIP_CACHE_DIR: "${{ github.workspace }}/.pip-cache"
      VENV_DIR: ${{ github.workspace }}/.venv
    steps:
      - name: Get Current Date
        id: date
        run: echo "::set-output name=date::$(date +'%Y-%m-%d')"

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0
        with:
          python-version: ${{matrix.version}}

      - name: "Checkout Code"
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Cache Pip Packages
        uses: actions/cache@6849a6489940f00c2f30c0fb92c6274307ccb58a # v4.1.2
        id: cache-pip
        with:
          path: ${{ env.PIP_CACHE_DIR }}
          key: pip-${{ steps.setup_python.outputs.python-version }}-${{ hashFiles('*requirements.txt') }}

      - name: Install pip deps
        run: |
          python -m pip install --no-compile --upgrade pip
          # Note: We install in three steps in order to satisfy requirements
          # from non default locations first. Installing the PyTorch CPU
          # wheels saves multiple minutes and a lot of bandwidth on runner setup.
          pip install --no-compile -r pytorch-cpu-requirements.txt
          pip install --no-compile -r requirements.txt -r sharktank/requirements-tests.txt -e sharktank/

          # Get latest working stable IREE release
          pip install iree-turbine==3.0.0

      - name: Run llama 8b f16 decomposed test
        run: pytest sharktank/tests/models/llama/benchmark_amdgpu_test.py -v -s --iree-hip-target=gfx942 --iree-device=hip://0 --run-quick-llama-test

      - name: Upload llama executable files
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3
        with:
          name: llama-files
          path: ${{ github.workspace }}/${{ steps.date.outputs.date }}
